{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STEP 4: Generating top-10 recommendations for test users\n",
      "==================================================\n",
      "Generating recommendations for 1389 test users...\n",
      "Processed 0/1389 users...\n",
      "Processed 100/1389 users...\n",
      "Processed 200/1389 users...\n",
      "Processed 300/1389 users...\n",
      "Processed 400/1389 users...\n",
      "Processed 500/1389 users...\n",
      "Processed 600/1389 users...\n",
      "Processed 700/1389 users...\n",
      "Processed 800/1389 users...\n",
      "Processed 900/1389 users...\n",
      "Processed 1000/1389 users...\n",
      "Processed 1100/1389 users...\n",
      "Processed 1200/1389 users...\n",
      "Processed 1300/1389 users...\n",
      "Recommendations generated for all 1389 users!\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Generate top-k recommendations for test users\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STEP 4: Generating top-10 recommendations for test users\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def get_top_n_recommendations(algo, trainset, user_id, n=10):\n",
    "    \"\"\"Get top N recommendations for a user\"\"\"\n",
    "    try:\n",
    "        # Get all items\n",
    "        all_items = set([trainset.to_raw_iid(iid) for iid in range(trainset.n_items)])\n",
    "        \n",
    "        # Get items the user has already rated\n",
    "        try:\n",
    "            user_inner_id = trainset.to_inner_uid(user_id)\n",
    "            user_rated = set([trainset.to_raw_iid(iid) for (iid, _) in trainset.ur[user_inner_id]])\n",
    "        except ValueError:\n",
    "            user_rated = set()\n",
    "        \n",
    "        # Items to recommend = all items minus rated items\n",
    "        items_to_recommend = list(all_items - user_rated)\n",
    "        \n",
    "        # Predict ratings for all these items (limit for speed)\n",
    "        predictions = []\n",
    "        for item_id in items_to_recommend[:500]:  # Limit for speed\n",
    "            pred = algo.predict(user_id, item_id)\n",
    "            predictions.append((item_id, pred.est))\n",
    "        \n",
    "        # Sort by predicted rating and return top N\n",
    "        predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [item for item, _ in predictions[:n]]\n",
    "    except Exception as e:\n",
    "        print(f\"Error for user {user_id}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Get unique test users\n",
    "test_users = test_df['user_id'].unique()\n",
    "print(f\"Generating recommendations for {len(test_users)} test users...\")\n",
    "\n",
    "# Generate recommendations for each model\n",
    "user_recommendations = {}\n",
    "\n",
    "for i, user_id in enumerate(test_users):\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Processed {i}/{len(test_users)} users...\")\n",
    "    \n",
    "    user_recommendations[user_id] = {\n",
    "        'knn': get_top_n_recommendations(knn_model, trainset, user_id, n=10),\n",
    "        'svd': get_top_n_recommendations(svd_model, trainset, user_id, n=10),\n",
    "        'top_pop': get_top_n_recommendations(top_pop_model, trainset, user_id, n=10)\n",
    "    }\n",
    "\n",
    "print(f\"Recommendations generated for all {len(test_users)} users!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating RMSE with fixed function...\n",
      "  TopPop: 6645 valid predictions, 0 errors\n",
      "  KNN: 6645 valid predictions, 0 errors\n",
      "  SVD: 6645 valid predictions, 0 errors\n",
      "\n",
      "------------------------------\n",
      "RMSE RESULTS\n",
      "------------------------------\n",
      "TopPop RMSE: 3.3354\n",
      "KNN RMSE: 0.9789\n",
      "SVD RMSE: 0.9333\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: RMSE Evaluation\n",
    "\n",
    "def calculate_rmse_fixed(model, test_tuples, model_name=\"\"):\n",
    "    \"\"\"Calculate RMSE with proper true ratings\"\"\"\n",
    "    predictions = []\n",
    "    errors = 0\n",
    "    \n",
    "    for user, item, true_rating in test_tuples:\n",
    "        try:\n",
    "            # Get prediction from model\n",
    "            pred = model.predict(user, item)\n",
    "            \n",
    "            if pred.est is not None and not np.isnan(pred.est):\n",
    "                predictions.append({\n",
    "                    'true': true_rating,\n",
    "                    'est': float(pred.est)\n",
    "                })\n",
    "            else:\n",
    "                errors += 1\n",
    "        except Exception as e:\n",
    "            errors += 1\n",
    "    \n",
    "    print(f\"  {model_name}: {len(predictions)} valid predictions, {errors} errors\")\n",
    "    \n",
    "    if len(predictions) == 0:\n",
    "        return float('nan')\n",
    "    \n",
    "    # Calculate RMSE manually\n",
    "    try:\n",
    "        squared_errors = [(p['true'] - p['est']) ** 2 for p in predictions]\n",
    "        mse = np.mean(squared_errors)\n",
    "        rmse = np.sqrt(mse)\n",
    "        return rmse\n",
    "    except Exception as e:\n",
    "        print(f\"  Error in manual RMSE calculation: {e}\")\n",
    "        return float('nan')\n",
    "\n",
    "# Calculate RMSE for each model\n",
    "print(\"\\nCalculating RMSE with fixed function...\")\n",
    "top_pop_rmse = calculate_rmse_fixed(top_pop_model, test_tuples, \"TopPop\")\n",
    "knn_rmse = calculate_rmse_fixed(knn_model, test_tuples, \"KNN\")\n",
    "svd_rmse = calculate_rmse_fixed(svd_model, test_tuples, \"SVD\")\n",
    "\n",
    "# Display RMSE results\n",
    "print(\"\\n\" + \"-\"*30)\n",
    "print(\"RMSE RESULTS\")\n",
    "print(\"-\"*30)\n",
    "print(f\"TopPop RMSE: {top_pop_rmse:.4f}\")\n",
    "print(f\"KNN RMSE: {knn_rmse:.4f}\")\n",
    "print(f\"SVD RMSE: {svd_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 6645 test interactions\n",
      "Found 1389 unique test users\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: Prepare test data\n",
    "\n",
    "# Convert test data to list of tuples\n",
    "test_tuples = [tuple(x) for x in test_df[['user_id', 'item_id', 'rating']].to_numpy()]\n",
    "print(f\"Prepared {len(test_tuples)} test interactions\")\n",
    "\n",
    "# Get unique test users\n",
    "test_users = test_df['user_id'].unique()\n",
    "print(f\"Found {len(test_users)} unique test users\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recreating TopPop model...\n",
      "TopPop model recreated with 10 popular items\n",
      "Top items: ['B0086VPUHI', 'B00BN5T30E', 'B07YBXFDYN', 'B00BGA9WK2', 'B007CM0K86']...\n",
      "\n",
      "Models and data loaded successfully!\n",
      "Train set size: 26580\n",
      "Test set size: 6645\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Load saved models and data\n",
    "\n",
    "# Load the cleaned data\n",
    "train_df = pd.read_parquet('cleaned_train.parquet')\n",
    "test_df = pd.read_parquet('cleaned_test.parquet')\n",
    "\n",
    "# Load the saved models\n",
    "with open('best_knn_model.pkl', 'rb') as f:\n",
    "    knn_model = pickle.load(f)\n",
    "\n",
    "with open('best_svd_model.pkl', 'rb') as f:\n",
    "    svd_model = pickle.load(f)\n",
    "\n",
    "with open('trainset.pkl', 'rb') as f:\n",
    "    trainset = pickle.load(f)\n",
    "\n",
    "# RECREATE TopPop model\n",
    "print(\"\\nRecreating TopPop model...\")\n",
    "top_items = pd.read_csv('top_items.csv')\n",
    "top_pop_items = top_items.head(10)['item_id'].tolist()\n",
    "top_pop_model = TopPop(top_pop_items)\n",
    "top_pop_model.fit(trainset)\n",
    "\n",
    "print(f\"TopPop model recreated with {len(top_pop_items)} popular items\")\n",
    "print(f\"Top items: {top_pop_items[:5]}...\")\n",
    "\n",
    "print(\"\\nModels and data loaded successfully!\")\n",
    "print(f\"Train set size: {len(train_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE THE TOPPOP CLASS\n",
    "\n",
    "class TopPop(AlgoBase):\n",
    "    def __init__(self, top_items_list=None):\n",
    "        AlgoBase.__init__(self)\n",
    "        self.top_items = top_items_list if top_items_list else []\n",
    "    \n",
    "    def fit(self, trainset):\n",
    "        self.trainset = trainset\n",
    "        return self\n",
    "    \n",
    "    def estimate(self, u, i):\n",
    "        try:\n",
    "            raw_iid = self.trainset.to_raw_iid(i)\n",
    "            if raw_iid in self.top_items:\n",
    "                return 5.0\n",
    "            else:\n",
    "                return 1.0\n",
    "        except:\n",
    "            return 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from surprise import AlgoBase, accuracy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
